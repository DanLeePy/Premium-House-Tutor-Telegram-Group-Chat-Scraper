{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lxml import html\n",
    "import requests\n",
    "import re\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "%load_ext lab_black"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_series(x, sub=False):\n",
    "    loc_list = []\n",
    "    if sub == False:\n",
    "        for i in range(len(text_list)):\n",
    "            loc = re.findall(x, text_list[i])\n",
    "            if len(loc) == 0:\n",
    "                loc_list.append(np.nan)\n",
    "            else:\n",
    "                loc_list.append(loc[0])\n",
    "    elif sub == True:\n",
    "        for i in range(len(text_list)):\n",
    "            loc = re.findall(x, re.sub(r\"\\(.*?\\)\", \"\", text_list[i]))\n",
    "            if len(loc) == 0:\n",
    "                loc_list.append(np.nan)\n",
    "            else:\n",
    "                loc_list.append(loc[0])\n",
    "    loc_list = pd.Series(loc_list)\n",
    "    return loc_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_table(y):\n",
    "    HtmlFile = open(y, \"r\", encoding=\"utf-8\")\n",
    "    source_code = HtmlFile.read()\n",
    "\n",
    "    soup = BeautifulSoup(source_code, \"html.parser\")\n",
    "\n",
    "    for foo in soup.find_all(\"div\", attrs={\"class\": \"text\"}):\n",
    "        text_list.append(foo.text)\n",
    "\n",
    "    sub_list = create_series(\"(?<=ASSIGNMENT).*?(?= @)\", True)\n",
    "    town_list = create_series(\"(?<=@).*?(?=Details)\")\n",
    "    post_list = create_series(\"\\d{6}\")\n",
    "    loc_list = create_series(\"(?<=Location:).*?(?=Duration)\")\n",
    "    dur_list = create_series(\"(?<=Duration:).*?(?:(?=Days)|(?=Timings))\")\n",
    "    day_list = create_series(\"(?:(?<=Days:)|(?<=Timings:)).*?(?=Fees)\")\n",
    "    fee_list = create_series(\"(?<=Fees:).*?(?=Tutor)\")\n",
    "    req_list = create_series(\"(?<=Requirements:).*?(?=Remarks)\")\n",
    "    rem_list = create_series(\"(?<=Remarks:).*?(?=.Interested)\")\n",
    "\n",
    "    data = pd.concat(\n",
    "        [\n",
    "            sub_list,\n",
    "            town_list,\n",
    "            post_list,\n",
    "            dur_list,\n",
    "            loc_list,\n",
    "            day_list,\n",
    "            fee_list,\n",
    "            req_list,\n",
    "            rem_list,\n",
    "        ],\n",
    "        axis=1,\n",
    "    )\n",
    "    data.columns = [\n",
    "        \"Subject\",\n",
    "        \"Town\",\n",
    "        \"Postal_Code\",\n",
    "        \"Duration\",\n",
    "        \"Address\",\n",
    "        \"Day\",\n",
    "        \"Fees\",\n",
    "        \"Requirements\",\n",
    "        \"Remarks\",\n",
    "    ]\n",
    "\n",
    "    data = data.dropna(how=\"all\")\n",
    "\n",
    "    data_dur = data[\"Duration\"].str.split(\"x\", n=1, expand=True)\n",
    "    data = pd.concat([data, data_dur], axis=1)\n",
    "    data = data.select_dtypes(include=\"object\").apply(lambda x: x.str.strip())\n",
    "    data = data.drop(columns=[\"Duration\"])\n",
    "    data = data.rename(columns={0: \"Frequency\", 1: \"Duration\"})\n",
    "\n",
    "    data[\"Duration\"] = data[\"Duration\"].str.lower()\n",
    "    data[\"minute\"] = data[\"Duration\"].str.contains(r\"min\")\n",
    "    data[\"hour\"] = data[\"Duration\"].str.contains(r\"(hour|hr)\")\n",
    "    data[\"Duration\"] = data[\"Duration\"].str.extract(r\"(\\d*)\")\n",
    "    data[\"Frequency\"] = data[\"Frequency\"].str.extract(r\"(\\d*)\")\n",
    "\n",
    "    data[\"Duration\"] = data[\"Duration\"].str.strip()\n",
    "    data[\"Frequency\"] = data[\"Frequency\"].str.strip()\n",
    "\n",
    "    data[\"Frequency\"] = data[\"Frequency\"].replace(\"\", 0)\n",
    "    data[\"Duration\"] = data[\"Duration\"].replace(\"\", 0)\n",
    "    data[\"Duration\"] = data[\"Duration\"].fillna(0)\n",
    "    data[\"Frequency\"] = data[\"Frequency\"].fillna(0)\n",
    "\n",
    "    data[\"Frequency\"] = data[\"Frequency\"].astype(float)\n",
    "    data[\"Duration\"] = data[\"Duration\"].astype(float)\n",
    "\n",
    "    # data[\"Duration\"] = data[\"Frequency\"] * data[\"Duration\"]\n",
    "\n",
    "    data[\"Duration\"] = np.where(\n",
    "        (((data[\"minute\"] == 1) & (data[\"hour\"] == 0)) | (data[\"Duration\"] >= 10)),\n",
    "        data[\"Duration\"] / 60,\n",
    "        data[\"Duration\"],\n",
    "    )\n",
    "\n",
    "    data[\"Fees\"] = data[\"Fees\"].str.extract(r\"(\\d*(?=[/âˆ’/-/]))\")\n",
    "\n",
    "    data[\"Day\"] = data[\"Day\"].str.lower()\n",
    "    data[\"Day\"] = data[\"Day\"].str.findall(pat)\n",
    "    data = data.dropna(subset=[\"Day\"])\n",
    "    data[\"Day\"] = data[\"Day\"].apply(lambda x: mapping(x))\n",
    "\n",
    "    data[\"Requirements\"] = data[\"Requirements\"].str.lower()\n",
    "\n",
    "    data[\"Female Req\"] = data[\"Requirements\"].str.contains(r\"female\")\n",
    "    data[\"Male Req\"] = data[\"Requirements\"].str.contains(r\"\\bmale\\b\")\n",
    "    data[\"MOE Req\"] = data[\"Requirements\"].str.contains(r\"\\bmoe\\b\")\n",
    "    data[\"Undegrad Req\"] = data[\"Requirements\"].str.contains(r\"undergrad\")\n",
    "    data[\"Grad Req\"] = data[\"Requirements\"].str.contains(r\"graduate\")\n",
    "    data[\"Full Time Req\"] = data[\"Requirements\"].str.contains(r\"full time\")\n",
    "    data[\"Part Time Req\"] = data[\"Requirements\"].str.contains(r\"part time\")\n",
    "    data[\"Exp Req\"] = data[\"Requirements\"].str.contains(r\"experience\")\n",
    "\n",
    "    data = data.drop_duplicates(subset=\"Postal_Code\", keep=\"first\")\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [],
   "source": [
    "msg_list = [\n",
    "    \"messages.html\",\n",
    "    \"messages2.html\",\n",
    "    \"messages3.html\",\n",
    "    \"messages4.html\",\n",
    "    \"messages5.html\",\n",
    "]\n",
    "\n",
    "pat = r\"({})\".format(\"|\".join(days.keys()))\n",
    "\n",
    "\n",
    "def find_day(x):\n",
    "    j = re.findall(pat, x)\n",
    "    return \",\".join(j)\n",
    "\n",
    "\n",
    "def mapping(data):\n",
    "    lst = []\n",
    "    for y in data:\n",
    "        num = days[y]\n",
    "        if num == 8:\n",
    "            num = np.random.randint(1, 6)\n",
    "        elif num == 9:\n",
    "            num = np.random.randint(6, 8)\n",
    "        lst.append(num)\n",
    "    return lst\n",
    "\n",
    "\n",
    "days = {\n",
    "    \"mon\": 1,\n",
    "    \"tues\": 2,\n",
    "    \"wed\": 3,\n",
    "    \"thurs\": 4,\n",
    "    \"fri\": 5,\n",
    "    \"sat\": 6,\n",
    "    \"sun\": 7,\n",
    "    \"weekday\": 8,\n",
    "    \"weekend\": 9,\n",
    "}\n",
    "\n",
    "text_list = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_comb = pd.DataFrame()\n",
    "\n",
    "for i in msg_list:\n",
    "    data = create_table(i)\n",
    "    data_comb = pd.concat([data_comb, data])\n",
    "\n",
    "data_comb = data_comb.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_comb.to_csv(\"data.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
